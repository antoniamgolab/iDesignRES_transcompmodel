{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547b94cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b0681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_key(key):\n",
    "    # Convert string key to a tuple\n",
    "    return safe_tuple_parser(key)\n",
    "\n",
    "def process_value(value):\n",
    "    # Convert string value to float\n",
    "    return float(value)\n",
    "\n",
    "def safe_tuple_parser(key):\n",
    "    \"\"\"\n",
    "    Safely parses string representations of nested \n",
    "    tuples into actual Python tuples.\n",
    "    Example: \"(2024, (1, 7, 0), (1, 8), 2024)\" -> (2024, (1, 7, 0), (1, 8), 2024)\n",
    "    \"\"\"\n",
    "    import ast  # Abstract Syntax Tree module for safe literal evaluation\n",
    "\n",
    "    # Remove outer quotes if present and use `ast.literal_eval`\n",
    "    try:\n",
    "        return ast.literal_eval(key)\n",
    "    except (SyntaxError, ValueError) as e:\n",
    "        raise ValueError(f\"Failed to parse key: {key}\") from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626c727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(case_study_name, input_file_name):\n",
    "    current_path = os.getcwd()\n",
    "    print(\"Current path:\", current_path)\n",
    "    file_results = os.path.normpath(current_path + \"/results\")\n",
    "    print(\"File results:\", os.path.normpath(file_results))\n",
    "    file_path = os.path.join(current_path, \"/results\")\n",
    "    print(file_path)\n",
    "    # Normalize the path\n",
    "    normalized_path = os.path.normpath(file_path)\n",
    "    print(\"Normalized path:\", normalized_path)\n",
    "\n",
    "    # reading input data \n",
    "    folder_input = os.path.normpath(current_path + \"/data\")\n",
    "    with open(folder_input + \"/\" + input_file_name) as file:\n",
    "        input_data = yaml.safe_load(file)\n",
    "\n",
    "    with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_n_fueling_dict.yaml\")) as file:\n",
    "        n_fueling_dict= yaml.safe_load(file)\n",
    "\n",
    "    # with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_budget_penalty_minus_dict.yaml\")) as file:\n",
    "    #     budget_penalty_minus_dict = yaml.safe_load(file)\n",
    "\n",
    "    # with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_budget_penalty_plus_dict.yaml\")) as file:\n",
    "    #     budget_penalty_plus_dict= yaml.safe_load(file)\n",
    "\n",
    "    # with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_budget_penalty_plus_yearly_dict.yaml\")) as file:\n",
    "    #     budget_penalty_plus_yearly_dict= yaml.safe_load(file)\n",
    "\n",
    "    # with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_budget_penalty_minus_yearly_dict.yaml\")) as file:\n",
    "    #     budget_penalty_minus_yearly_dict= yaml.safe_load(file)\n",
    "\n",
    "    # with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_detour_time_dict.yaml\")) as file:\n",
    "    #     detour_time_dict= yaml.safe_load(file)\n",
    "\n",
    "    # with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_f_dict.yaml\")) as file:\n",
    "    #     f_dict= yaml.safe_load(file)\n",
    "\n",
    "    with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_h_dict.yaml\")) as file:\n",
    "        h_dict= yaml.safe_load(file)\n",
    "\n",
    "    # with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_h_exist_dict.yaml\")) as file:\n",
    "    #     h_exist_dict= yaml.safe_load(file)\n",
    "\n",
    "    # with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_h_minus_dict.yaml\")) as file:\n",
    "    #     h_minus_dict= yaml.safe_load(file)\n",
    "\n",
    "    # with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_h_plus_dict.yaml\")) as file:\n",
    "    #     h_plus_dict= yaml.safe_load(file)\n",
    "\n",
    "    with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_q_fuel_infr_plus_dict.yaml\")) as file:\n",
    "        q_fuel_infr_plus_dict= yaml.safe_load(file)\n",
    "\n",
    "    with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_q_fuel_infr_plus_by_route_dict.yaml\")) as file:\n",
    "        q_fuel_infr_plus_by_route_dict= yaml.safe_load(file)\n",
    "\n",
    "    # with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_q_mode_infr_plus_dict.yaml\")) as file:\n",
    "    #     q_mode_infr_plus_dict= yaml.safe_load(file)\n",
    "\n",
    "    with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_s.yaml\")) as file:\n",
    "        s_dict= yaml.safe_load(file)\n",
    "\n",
    "    with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_vot_dt_dict.yaml\")) as file:\n",
    "        vot_dt_dict = yaml.safe_load(file)\n",
    "    \n",
    "    # budget_penalty_minus = {process_key(key): process_value(value) for key, value in budget_penalty_minus_dict.items()}\n",
    "    # budget_penalty_plus = {process_key(key): process_value(value) for key, value in budget_penalty_plus_dict.items()}\n",
    "    # detour_time = {process_key(key): process_value(value) for key, value in detour_time_dict.items()}\n",
    "    # f = {process_key(key): process_value(value) for key, value in f_dict.items()}\n",
    "    h = {process_key(key): process_value(value) for key, value in h_dict.items()}\n",
    "    # h_exist = {process_key(key): process_value(value) for key, value in h_exist_dict.items()}\n",
    "    # h_minus = {process_key(key): process_value(value) for key, value in h_minus_dict.items()}\n",
    "    # h_plus = {process_key(key): process_value(value) for key, value in h_plus_dict.items()}\n",
    "    q_fuel_infr_plus = {process_key(key): process_value(value) for key, value in q_fuel_infr_plus_dict.items()}\n",
    "    q_fuel_infr_plus_by_route = {process_key(key): process_value(value) for key, value in q_fuel_infr_plus_by_route_dict.items()}\n",
    "    # q_mode_infr_plus = {process_key(key): process_value(value) for key, value in q_mode_infr_plus_dict.items()}\n",
    "    s = {process_key(key): process_value(value) for key, value in s_dict.items()}\n",
    "    n_fueling = {process_key(key): process_value(value) for key, value in n_fueling_dict.items()}\n",
    "    vot_dt_dict = {process_key(key): process_value(value) for key, value in vot_dt_dict.items()}\n",
    "    # # detour_time = {}\n",
    "    # # n_fueling = {}\n",
    "    # output_data = {\"budget_penalty_minus\": budget_penalty_minus, \"budget_penalty_plus\": budget_penalty_plus, \"detour_time\": detour_time, \"f\": f, \"h\": h, \"h_exist\": h_exist, \"h_minus\": h_minus, \"h_plus\": h_plus, \"q_fuel_infr_plus\": q_fuel_infr_plus, \"q_mode_infr_plus\": q_mode_infr_plus, \"s\": s, \"n_fueling\": n_fueling}\n",
    "    output_data = {\"h\": h, \"s\": s, \"q_fuel_infr_plus\": q_fuel_infr_plus, \"q_fuel_infr_plus_by_route\": q_fuel_infr_plus_by_route, \"n_fueling\": n_fueling, \"vot_dt_dict\": vot_dt_dict}  # Assuming you only want to return f_dict for now\n",
    "    return input_data, output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc6b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# case_study_names = {\"cs_2025-06-02_18-48-03\": \"Distributed Densification\",\n",
    "#                    \"cs_2025-06-03_07-53-03\": \"Balanced Densification\",\n",
    "#                    \"cs_2025-06-02_13-51-34\": \"Centralized Densification\"}\n",
    "# # case_studies = [\"cs_2025-04-03_09-52-20\", \"cs_2025-04-03_11-23-29\", \"cs_2025-03-27_11-00-01\"]\n",
    "# input_files = {\n",
    "#     \"cs_2025-06-02_18-48-03\": \"transport_data_v1_ONENODE_distributed.yaml\",\n",
    "#     \"cs_2025-06-03_07-53-03\": \"transport_data_v1_ONENODE_balanced.yaml\",\n",
    "#     \"cs_2025-06-02_13-51-34\": \"transport_data_v1_ONENODE_concentrated.yaml\"\n",
    "    \n",
    "# }\n",
    "case_study_names = {\"cs_2025-08-04_20-17-12\": \"Distributed Densification\",\n",
    "                   \"cs_2025-07-10_09-52-50\": \"Balanced Densification\",\n",
    "                   \"cs_2025-07-02_07-57-57\": \"Centralized Densification\"}\n",
    "# case_studies = [\"cs_2025-04-03_09-52-20\", \"cs_2025-04-03_11-23-29\", \"cs_2025-03-27_11-00-01\"]\n",
    "input_files = {\n",
    "    \"cs_2025-08-04_20-17-12\": \"transport_data_v1_ONENODE_distributed_cut_demand.yaml\",\n",
    "    \"cs_2025-07-10_09-52-50\": \"transport_data_v1_ONENODE_balanced_cut_demand.yaml\",\n",
    "    \"cs_2025-07-02_07-57-57\": \"transport_data_v1_ONENODE_concentrated_cut_demand.yaml\"\n",
    "    \n",
    "}\n",
    "case_study_output = {}\n",
    "case_study_input = {}\n",
    "for cs in case_study_names.keys():\n",
    "    input_data, output_data = read_data(cs, input_files[cs])\n",
    "    case_study_output[case_study_names[cs]] = output_data\n",
    "    case_study_input[case_study_names[cs]] = input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d9f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2040 \n",
    "y_init = 2020\n",
    "g_init = 2020-25\n",
    "Y_end = 2050\n",
    "tech_split_per_case_study = {}\n",
    "for case_study_name, output_data in case_study_output.items():\n",
    "    input_data = case_study_input[case_study_name]\n",
    "\n",
    "    financial_status = input_data[\"FinancialStatus\"]\n",
    "    odpair_list = input_data[\"Odpair\"]\n",
    "    financial_status_dict = {item[\"name\"]: item for item in financial_status}\n",
    "    odpair_list_dict = {item[\"id\"]: item for item in odpair_list}\n",
    "    techvehicle_list = input_data[\"TechVehicle\"]\n",
    "    techvehicle_list_dict = {item[\"id\"]: item for item in techvehicle_list}\n",
    "    h = output_data[\"h\"]\n",
    "    tech_split_by_fs = {}\n",
    "    for fs in financial_status_dict.keys():\n",
    "        h_total = sum([h.get((year, r, tv, g)) for r in odpair_list_dict.keys() for tv in techvehicle_list_dict.keys() for g in range(g_init, year) if (year, r, tv, g) in h and fs == odpair_list_dict[r][\"financial_status\"]])\n",
    "        h_elec = sum([h.get((year, r, tv, g)) for r in odpair_list_dict.keys() for tv in techvehicle_list_dict.keys() for g in range(g_init, year) if (year, r, tv, g) in h and fs == odpair_list_dict[r][\"financial_status\"] and techvehicle_list_dict[tv][\"technology\"] == 2])\n",
    "        print(h_elec, h_total, fs)\n",
    "        if h_elec > 0:\n",
    "            tech_split_by_fs[fs] = h_elec / h_total\n",
    "        else:\n",
    "            tech_split_by_fs[fs] = 0.0\n",
    "    tech_split_per_case_study[case_study_name] = tech_split_by_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885603a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"Garamond\",\n",
    "    \"font.size\": 18,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2443aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_labels = {\"Distributed Densification\": r\"$n^{\\textrm{points per site}} = 2$ (Distributed expansion)\",\n",
    "                 \"Centralized Densification\": r\"$n^{\\textrm{points per site}} = 40$ (Centralized expansion)\",\n",
    "                 \"Balanced Densification\": r\"$n^{\\textrm{points per site}} = 10$\"}\n",
    "Income_level_labels = {\n",
    "    \"First quintile\": \"Very low income\",\n",
    "    \"Second quintile\": \"Low income\",\n",
    "    \"Third quintile\": \"Medium low income\",\n",
    "    \"Fourth quintile\": \"High income\",\n",
    "    \"Fifth quintile\": \"Very high income\",\n",
    "}\n",
    "filtered_tech_split = {}\n",
    "for case, split in tech_split_per_case_study.items():\n",
    "    filtered_tech_split[case] = {fs: split[fs] for fs in Income_level_labels if fs in split}\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "income_classes = list(Income_level_labels.keys())\n",
    "case_studies = list(filtered_tech_split.keys())\n",
    "\n",
    "# Prepare data for plotting\n",
    "data = []\n",
    "for case in case_studies:\n",
    "    values = [filtered_tech_split[case].get(fs, 0) for fs in income_classes]\n",
    "    data.append(values)\n",
    "\n",
    "x = np.arange(len(income_classes))\n",
    "width = 0.25\n",
    "colors_by_case = {\n",
    "    \"Distributed Densification\": \"#087E8B\",\n",
    "    \"Balanced Densification\": \"#FF5A5F\",\n",
    "    \"Centralized Densification\": \"#3C3C3C\"\n",
    "}\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "for i, case in enumerate(case_studies):\n",
    "    ax.scatter(x, data[i], label=actual_labels[case], s=100, color=colors_by_case[case], alpha=0.8, marker=\"h\")  # All cases share the same x positions\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([Income_level_labels[fs] for fs in income_classes], rotation=30)\n",
    "ax.set_ylabel(\"Share of electric vehicles\")\n",
    "ax.set_title(\"Share of electric vehicles by income class and roll-out strategy\")\n",
    "ax.legend(fontsize=12, title=\"Roll-out strategy\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.grid(True, zorder=-1)\n",
    "plt.xlabel(\"Consumer group by income level\")\n",
    "\n",
    "plt.show()\n",
    "# print(tech_split_per_case_study[\"Distributed Densification\"][\"First quintile\"])\n",
    "print(income_classes)\n",
    "  \n",
    "fig.savefig(\"share_electric_vehicles_by_income_and_strategy.pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4441f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9574593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the fueling allocation\n",
    "year = 2040\n",
    "fueled_energy_by_fs = {}\n",
    "for case_study_name, output_data in case_study_output.items():\n",
    "    input_data = case_study_input[case_study_name]\n",
    "\n",
    "    s = output_data[\"s\"]\n",
    "    financial_status = input_data[\"FinancialStatus\"]\n",
    "    odpair_list = input_data[\"Odpair\"]\n",
    "    financial_status_dict = {item[\"name\"]: item for item in financial_status}\n",
    "    odpair_list_dict = {item[\"id\"]: item for item in odpair_list}\n",
    "    techvehicle_list = input_data[\"TechVehicle\"]\n",
    "    fuel_list = input_data[\"Fuel\"]\n",
    "    geographic_elements = input_data[\"GeographicElement\"]\n",
    "    geographic_elements_dict = {item[\"id\"]: item for item in geographic_elements}\n",
    "    techvehicle_list_dict = {item[\"id\"]: item for item in techvehicle_list}\n",
    "    fuel_list_dict = {item[\"id\"]: item for item in fuel_list}\n",
    "    l = input_data[\"FuelingInfrTypes\"]\n",
    "    l_dict = {item[\"id\"]: item for item in l}\n",
    "    fueled_energy_by_fs_by_cs = {}\n",
    "    for fs in financial_status_dict.keys():\n",
    "        for l in l_dict.keys():\n",
    "            energy_total = sum([s.get((year, (1, r, odpair_list_dict[r][\"path_id\"], geo), tv, (f, l), g)) for geo in geographic_elements_dict.keys() for f in fuel_list_dict.keys() for r in odpair_list_dict.keys() for tv in techvehicle_list_dict.keys() for g in range(g_init, year) if (year, (1, r, odpair_list_dict[r][\"path_id\"], geo), tv, (f, l), g) in s and fs == odpair_list_dict[r][\"financial_status\"]])\n",
    "            # if case_study_name == \"Centralized Densification\":\n",
    "            #     # print(\"Energy total for fs:\", fs, \"and l:\", l, \"is\", energy_total)\n",
    "            #     fueled_energy_by_fs_by_cs[(fs, l)] = energy_total * 1000\n",
    "            # else:\n",
    "                # print(\"Energy total for fs:\", fs, \"and l:\", l, \"is\", energy_total)\n",
    "            fueled_energy_by_fs_by_cs[(fs, l)] = energy_total\n",
    "    \n",
    "    \n",
    "    fueled_energy_by_fs[case_study_name] = fueled_energy_by_fs_by_cs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ad9372",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fueled_energy_by_fs[\"Centralized Densification\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dc5717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "\n",
    "print(fueled_energy_by_fs)\n",
    "\n",
    "# Prepare data for plotting\n",
    "income_classes = ['First quintile', 'Second quintile', 'Third quintile', 'Fourth quintile', 'Fifth quintile']\n",
    "case_studies = list(fueled_energy_by_fs.keys())\n",
    "fueling_type_ids = list(l_dict.keys())  # All fueling types\n",
    "\n",
    "# Get fueling type names for legend\n",
    "fueling_type_names = [l_dict[lid]['fueling_type'] for lid in fueling_type_ids]\n",
    "fueling_type_colors = {\n",
    "    'home': '#72DDF7',\n",
    "    'work': '#FFBE0B',\n",
    "    'public_fast': '#C1839F',\n",
    "    'public_slow': '#3C3C3C',\n",
    "    'public_fossil': '#A0A0A0'\n",
    "}\n",
    "case_study_colors = {\n",
    "    \"Distributed Densification\": \"#087E8B\",\n",
    "    \"Balanced Densification\": \"#FF5A5F\",\n",
    "    \"Centralized Densification\": \"#3C3C3C\"\n",
    "}\n",
    "# Prepare data: dict[case][fueling_type][income_class]\n",
    "data = {case: {ftype: [] for ftype in fueling_type_ids} for case in case_studies}\n",
    "for case in case_studies:\n",
    "    for lid in fueling_type_ids:\n",
    "        for fs in income_classes:\n",
    "            value = fueled_energy_by_fs[case].get((fs, lid), 0)\n",
    "            data[case][lid].append(value)\n",
    "\n",
    "x = np.arange(len(income_classes))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "for i, case in enumerate(case_studies):\n",
    "    bottom = np.zeros(len(income_classes))\n",
    "    for lid in fueling_type_ids:\n",
    "        # Scale values to 10^-6 (i.e., from Wh to GWh if original is Wh)\n",
    "        values = np.array(data[case][lid]) * 1e-6\n",
    "        color = fueling_type_colors.get(l_dict[lid]['fueling_type'], None)\n",
    "        ax.bar(x + i * width, values, width=width, bottom=bottom, \n",
    "               label=l_dict[lid]['fueling_type'] if i == 0 else \"\", \n",
    "               color=color, alpha=0.8, edgecolor=case_study_colors.get(case, \"black\"), linewidth=2)\n",
    "        bottom += values\n",
    "\n",
    "# Custom legend for fueling types\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "\n",
    "fueling_type_handles = [\n",
    "    Patch(facecolor=fueling_type_colors[l_dict[lid]['fueling_type']],\n",
    "          label=l_dict[lid]['fueling_type'],\n",
    "          edgecolor='none')\n",
    "    for lid in fueling_type_ids\n",
    "]\n",
    "fueling_type_labels = [l_dict[lid]['fueling_type'] for lid in fueling_type_ids]\n",
    "\n",
    "case_patches = [Patch(facecolor='white', edgecolor=case_study_colors[cs], linewidth=2, label=cs) for cs in case_studies]\n",
    "case_labels = case_studies\n",
    "\n",
    "combined_handles = fueling_type_handles + case_patches\n",
    "combined_labels = fueling_type_labels + case_labels\n",
    "\n",
    "ax.legend(combined_handles, combined_labels, title=\"Fueling type / Roll-out strategy\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels([Income_level_labels[fs] for fs in income_classes], rotation=30)\n",
    "ax.set_ylabel(\"Fueled energy (GWh)\")\n",
    "ax.set_title(\"Fueled energy by income class, roll-out strategy, and fueling type\")\n",
    "ax.text(0.5, 50, \"oasch\", ha='center', va='bottom', fontsize=0.5, fontweight='bold')\n",
    "plt.grid(True, axis='y', zorder=-1)\n",
    "plt.xlabel(\"Consumer group by income level\")\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"fueled_energy_by_income_fuelingtype_casestudy.pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57943c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stacked bars for each case study as subplots in a single figure\n",
    "\n",
    "# Plot fueled energy by income class, roll-out strategy, and fueling type as subplots\n",
    "actual_labels = {\"Distributed Densification\": r\"$n^{\\textrm{points per site}} = 2$\\newline(Distributed expansion)\",\n",
    "                 \"Centralized Densification\": r\"$n^{\\textrm{points per site}} = 40$\\newline(Centralized expansion)\",\n",
    "                 \"Balanced Densification\": r\"$n^{\\textrm{points per site}} = 10$\\\\\"}\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "case_studies = list(fueled_energy_by_fs.keys())\n",
    "income_classes = ['First quintile', 'Second quintile', 'Third quintile', 'Fourth quintile', 'Fifth quintile']\n",
    "fueling_type_ids = list(l_dict.keys())\n",
    "fueling_type_colors = {\n",
    "    'home': '#72DDF7',\n",
    "    'work': '#FFBE0B',\n",
    "    'public_fast': '#C1839F',\n",
    "    'public_slow': '#3C3C3C',\n",
    "    'public_fossil': '#A0A0A0'\n",
    "}\n",
    "\n",
    "for idx, case in enumerate(case_studies):\n",
    "    ax = axes[idx]\n",
    "    bottom = np.zeros(len(income_classes))\n",
    "    for lid in fueling_type_ids:\n",
    "        # Scale values to 10^-6 (i.e., from Wh to GWh if original is Wh)\n",
    "        values = np.array([fueled_energy_by_fs[case].get((fs, lid), 0) for fs in income_classes]) * 1e-6\n",
    "        color = fueling_type_colors.get(l_dict[lid]['fueling_type'], None)\n",
    "        ax.bar(np.arange(len(income_classes)), values, width=0.7, bottom=bottom, \n",
    "               label=l_dict[lid]['fueling_type'], color=color, alpha=0.8)\n",
    "        bottom += values\n",
    "    ax.set_title(actual_labels[case])\n",
    "    ax.set_xticks(np.arange(len(income_classes)))\n",
    "    ax.set_xticklabels([Income_level_labels[fs] for fs in income_classes], rotation=90)\n",
    "    if idx == 0:\n",
    "        ax.set_ylabel(\"Fueled energy (GWh)\")\n",
    "    ax.set_xlabel(\"Consumer group by income level\")\n",
    "    ax.grid(axis='y', zorder=-1)\n",
    "    if idx == 2:\n",
    "        ax.legend(title=\"Fueling Infrastructure Type\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "fig.suptitle(\"Fueled energy by income class, roll-out strategy, and fueling type\", fontsize=25)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d024124b",
   "metadata": {},
   "source": [
    "# Plotting development in charging infrastructures by type \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddf5564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_dict(target_dict, list_of_dicts):\n",
    "    \"\"\"\n",
    "    Finds and returns the first dictionary in the list that matches\n",
    "    the target dictionary in terms of all key-value pairs.\n",
    "\n",
    "    Parameters:\n",
    "        target_dict (dict): The dictionary to match.\n",
    "        list_of_dicts (list): List of dictionaries to search.\n",
    "\n",
    "    Returns:\n",
    "        dict or None: The matching dictionary, or None if not found.\n",
    "    \"\"\"\n",
    "    for d in list_of_dicts:\n",
    "        if all(d.get(k) == v for k, v in target_dict.items()):\n",
    "            return d\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80067fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_fuel_by_type_by_year_by_case_study = {}\n",
    "y_init = 2020\n",
    "Y = 61\n",
    "Y_end = y_init + Y\n",
    "for case_study_name, output_data in case_study_output.items():\n",
    "    input_data = case_study_input[case_study_name]\n",
    "\n",
    "    q_fuel_infr_plus = output_data[\"q_fuel_infr_plus\"]\n",
    "    q_fuel_infr_plus_by_route = output_data[\"q_fuel_infr_plus_by_route\"]\n",
    "    odpair_list = input_data[\"Odpair\"]\n",
    "    odpair_list_dict = {item[\"id\"]: item for item in odpair_list}\n",
    "    techvehicle_list = input_data[\"TechVehicle\"]\n",
    "    fuel_list = input_data[\"Fuel\"]\n",
    "    investment_period = input_data[\"Model\"][\"investment_period\"]\n",
    "    geographic_elements = input_data[\"GeographicElement\"]\n",
    "    InitialFuelingInfr_list = input_data[\"InitialFuelingInfr\"]\n",
    "    \n",
    "    InitialFuelingInfr_dict = {item[\"id\"]: item for item in InitialFuelingInfr_list}\n",
    "    geographic_elements_dict = {item[\"id\"]: item for item in geographic_elements}\n",
    "    techvehicle_list_dict = {item[\"id\"]: item for item in techvehicle_list}\n",
    "    fuel_list_dict = {item[\"id\"]: item for item in fuel_list}\n",
    "    l_list = input_data[\"FuelingInfrTypes\"]\n",
    "    l_dict = {item[\"id\"]: item for item in l_list}\n",
    "    q_fuel_by_type_by_year = {}\n",
    "    for year in range(y_init, Y_end):\n",
    "        q_fuel_by_type_by_year[year] = {}\n",
    "        for fs in financial_status_dict.keys():\n",
    "            for l in l_dict.keys():\n",
    "                for geo in geographic_elements_dict.keys():\n",
    "                    for f in fuel_list_dict.keys():\n",
    "                        if l < 4:\n",
    "                            match_to_find = {\n",
    "                                \"fuel\": fuel_list_dict[f][\"name\"],\n",
    "                                \"type\": l_dict[l][\"fueling_type\"],\n",
    "                                \"allocation\": geo,\n",
    "                            }\n",
    "                            if not find_matching_dict(match_to_find, InitialFuelingInfr_list) == None:\n",
    "                                matching_init = find_matching_dict(match_to_find, InitialFuelingInfr_list)\n",
    "                                init_fuel_infr = matching_init[\"installed_kW\"]\n",
    "                            else:\n",
    "                                init_fuel_infr = 0\n",
    "\n",
    "                            if l_dict[l][\"fueling_type\"] not in [\"home\"]:\n",
    "                                cap_total = init_fuel_infr + sum([q_fuel_infr_plus.get((y, (f, l), geo), 0) for y in range(y_init, year+1) for f in fuel_list_dict.keys()])\n",
    "                                q_fuel_by_type_by_year[year][l] = cap_total\n",
    "                            else: \n",
    "                                cap_total = init_fuel_infr + sum([q_fuel_infr_plus_by_route.get((y, r, (f, l), geo), 0) for y in range(y_init, year+1) for r in odpair_list_dict.keys() for f in fuel_list_dict.keys()])\n",
    "                                q_fuel_by_type_by_year[year][l] = cap_total\n",
    "\n",
    "    \n",
    "    q_fuel_by_type_by_year_by_case_study[case_study_name] = q_fuel_by_type_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec175b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stacked bars for each case study: fueling infrastructure by year and type\n",
    "\n",
    "for case_study, yearly_data in q_fuel_by_type_by_year_by_case_study.items():\n",
    "    years = sorted(yearly_data.keys())\n",
    "    l_ids = list(next(iter(yearly_data.values())).keys())\n",
    "    # Prepare data for each fueling type\n",
    "    data_by_type = {l_id: [yearly_data[year].get(l_id, 0) for year in years] for l_id in l_ids}\n",
    "    # Get fueling type names for legend\n",
    "    fueling_type_names = [l_dict[l_id]['fueling_type'] for l_id in l_ids]\n",
    "    fueling_type_colors = {\n",
    "        'home': '#72DDF7',\n",
    "        'work': '#FFBE0B',\n",
    "        'public_fast': '#C1839F',\n",
    "        'public_slow': '#3C3C3C',\n",
    "        'public_fossil': '#A0A0A0'\n",
    "    }\n",
    "    colors = [fueling_type_colors.get(l_dict[l_id]['fueling_type'], None) for l_id in l_ids]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    bottom = np.zeros(len(years))\n",
    "    for idx, l_id in enumerate(l_ids):\n",
    "        values = np.array(data_by_type[l_id]) * 1e-3  # Convert to MW if needed\n",
    "        ax.bar(years, values, bottom=bottom, label=l_dict[l_id]['fueling_type'], color=colors[idx], width=0.8)\n",
    "        bottom += values\n",
    "\n",
    "    ax.set_title(f\"Development of Charging Infrastructure by Type\\n{case_study}\")\n",
    "    ax.set_xlabel(\"Year\")\n",
    "    ax.set_ylabel(\"Installed Capacity (MW)\")\n",
    "    ax.legend(title=\"Fueling Infrastructure Type\")\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis='y', zorder=-1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2cf2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detour timing for public charging infrastructure \n",
    "# fast vs. slow charging + different cases ()\n",
    "\n",
    "# what do i new for this to reverse ingeneer the detour time? \n",
    "\n",
    "dt_by_case = {}\n",
    "for case_study_name, output_data in case_study_output.items():\n",
    "    input_data = case_study_input[case_study_name]\n",
    "    output_data = case_study_output[case_study_name]\n",
    "\n",
    "    vot_dt_dict = output_data[\"vot_dt_dict\"]\n",
    "    n_fueling = output_data[\"n_fueling\"]\n",
    "    geometric_elements = input_data[\"GeographicElement\"]\n",
    "    fueling_infr_types = input_data[\"FuelingInfrTypes\"]\n",
    "    geographic_elements_dict = {item[\"id\"]: item for item in geometric_elements}\n",
    "    fueling_infr_types_dict = {item[\"id\"]: item for item in fueling_infr_types}\n",
    "    financial_status = input_data[\"FinancialStatus\"]\n",
    "    techvehicle_list = input_data[\"TechVehicle\"]\n",
    "    techvehicle_list_dict = {item[\"id\"]: item for item in techvehicle_list}\n",
    "    financial_status_dict = {item[\"name\"]: item for item in financial_status}\n",
    "    odpair_list = input_data[\"Odpair\"]\n",
    "    odpair_list_dict = {item[\"id\"]: item for item in odpair_list}\n",
    "    path_list = input_data[\"Path\"]\n",
    "    path_list_dict = {item[\"id\"]: item for item in path_list}\n",
    "    fuel_list = input_data[\"Fuel\"]\n",
    "    fuel_list_dict = {item[\"id\"]: item for item in fuel_list}\n",
    "    init_detour_time = input_data[\"InitDetourTime\"]\n",
    "    # Create a dictionary with keys as (fuel_infr_type, location)\n",
    "    init_detour_time_dict = {}\n",
    "    for item in init_detour_time:\n",
    "        fuel_infr_type = item.get(\"id\")\n",
    "        location = item.get(\"location\")\n",
    "        key = (fuel_infr_type, location)\n",
    "        init_detour_time_dict[key] = item\n",
    "    dt_by_year = {}\n",
    "    for l_id in fueling_infr_types_dict.keys():\n",
    "        if fueling_infr_types_dict[l_id][\"fueling_type\"] in [\"public_fast\", \"public_slow\"]:\n",
    "            dt_by_year[fueling_infr_types_dict[l_id][\"fueling_type\"]] = {}\n",
    "            for vot_dt_key, vot_dt_value in vot_dt_dict.items():\n",
    "                if round(vot_dt_value) > 0 and vot_dt_key[1][3] == l_id:\n",
    "                    year = vot_dt_key[0]\n",
    "                    geo = vot_dt_key[1][0]\n",
    "                    _omega = 0\n",
    "                    for r_id in odpair_list_dict.keys():\n",
    "                        path_id = odpair_list_dict[r_id][\"path_id\"]\n",
    "                        sequence = path_list_dict[path_id][\"sequence\"]\n",
    "                        for item in sequence:\n",
    "                            if item == geo:\n",
    "                                financial_status_of_r = odpair_list_dict[r_id][\"financial_status\"]\n",
    "                                vot = financial_status_dict[financial_status_of_r][\"VoT\"]\n",
    "                                _omega += sum(\n",
    "                                    n_fueling[year, (1, r_id, path_id, geo), tv, (f, l), g]\n",
    "                                    for y in range(y_init, year+1)\n",
    "                                    for tv in techvehicle_list_dict.keys()\n",
    "                                    for f in fuel_list_dict.keys()\n",
    "                                    for l in fueling_infr_types_dict.keys()\n",
    "                                    for g in range(g_init, year)\n",
    "                                    if (year, (1, r_id, path_id, geo), tv, (f, l), g) in n_fueling\n",
    "                                ) * vot \n",
    "                    if _omega > 0:\n",
    "                        dt_by_year[fueling_infr_types_dict[l_id][\"fueling_type\"]][year] = vot_dt_value / _omega\n",
    "                    else:\n",
    "                        init_dt = init_detour_time_dict.get((l_id, geographic_elements_dict[geo][\"name\"]), {}).get(\"detour_time\", 0)\n",
    "                        dt_by_year[fueling_infr_types_dict[l_id][\"fueling_type\"]][year] = init_dt\n",
    "    dt_by_case[case_study_name] = dt_by_year\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "antoniasenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
