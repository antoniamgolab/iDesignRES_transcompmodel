{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization for Publication\n",
    "\n",
    "Answering the following research questions:\n",
    "\n",
    "* How is the increase of the density of the public fast-charging infrastructure network affecting the adoption of battery-eletric vehicles in different income classes?\n",
    "* Is there a spill-over effect of local public charging infrastructure investments on the adoption of battery-electric passenger "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_key(key):\n",
    "    # Convert string key to a tuple\n",
    "    return safe_tuple_parser(key)\n",
    "\n",
    "def process_value(value):\n",
    "    # Convert string value to float\n",
    "    return float(value)\n",
    "\n",
    "def safe_tuple_parser(key):\n",
    "    \"\"\"\n",
    "    Safely parses string representations of nested tuples into actual Python tuples.\n",
    "    Example: \"(2024, (1, 7, 0), (1, 8), 2024)\" -> (2024, (1, 7, 0), (1, 8), 2024)\n",
    "    \"\"\"\n",
    "    import ast  # Abstract Syntax Tree module for safe literal evaluation\n",
    "\n",
    "    # Remove outer quotes if present and use `ast.literal_eval`\n",
    "    try:\n",
    "        return ast.literal_eval(key)\n",
    "    except (SyntaxError, ValueError) as e:\n",
    "        raise ValueError(f\"Failed to parse key: {key}\") from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(case_study_name, input_file_name):\n",
    "    current_path = os.getcwd()\n",
    "    print(\"Current path:\", current_path)\n",
    "    file_results = os.path.normpath(current_path + \"/results\")\n",
    "    print(\"File results:\", os.path.normpath(file_results))\n",
    "    file_path = os.path.join(current_path, \"/results\")\n",
    "    print(file_path)\n",
    "    # Normalize the path\n",
    "    normalized_path = os.path.normpath(file_path)\n",
    "    print(\"Normalized path:\", normalized_path)\n",
    "\n",
    "    # reading input data \n",
    "    folder_input = os.path.normpath(current_path + \"/Basque country/data\")\n",
    "    with open(folder_input + \"/\" + input_file_name) as file:\n",
    "        input_data = yaml.safe_load(file)\n",
    "\n",
    "    with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_n_fueling_dict.yaml\")) as file:\n",
    "        n_fueling_dict= yaml.safe_load(file)\n",
    "\n",
    "    with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_budget_penalty_minus_dict.yaml\")) as file:\n",
    "        budget_penalty_minus_dict = yaml.safe_load(file)\n",
    "\n",
    "    with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_budget_penalty_plus_dict.yaml\")) as file:\n",
    "        budget_penalty_plus_dict= yaml.safe_load(file)\n",
    "\n",
    "    with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_detour_time_dict.yaml\")) as file:\n",
    "        detour_time_dict= yaml.safe_load(file)\n",
    "\n",
    "    with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_f_dict.yaml\")) as file:\n",
    "        f_dict= yaml.safe_load(file)\n",
    "\n",
    "    with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_h_dict.yaml\")) as file:\n",
    "        h_dict= yaml.safe_load(file)\n",
    "\n",
    "    with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_h_exist_dict.yaml\")) as file:\n",
    "        h_exist_dict= yaml.safe_load(file)\n",
    "\n",
    "    with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_h_minus_dict.yaml\")) as file:\n",
    "        h_minus_dict= yaml.safe_load(file)\n",
    "\n",
    "    with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_h_plus_dict.yaml\")) as file:\n",
    "        h_plus_dict= yaml.safe_load(file)\n",
    "\n",
    "    with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_q_fuel_infr_plus_dict.yaml\")) as file:\n",
    "        q_fuel_infr_plus_dict= yaml.safe_load(file)\n",
    "\n",
    "    with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_q_mode_infr_plus_dict.yaml\")) as file:\n",
    "        q_mode_infr_plus_dict= yaml.safe_load(file)\n",
    "\n",
    "    with open(os.path.normpath(file_results + \"/\" + case_study_name + \"_s.yaml\")) as file:\n",
    "        s_dict= yaml.safe_load(file)\n",
    "    \n",
    "    budget_penalty_minus = {process_key(key): process_value(value) for key, value in budget_penalty_minus_dict.items()}\n",
    "    budget_penalty_plus = {process_key(key): process_value(value) for key, value in budget_penalty_plus_dict.items()}\n",
    "    detour_time = {process_key(key): process_value(value) for key, value in detour_time_dict.items()}\n",
    "    f = {process_key(key): process_value(value) for key, value in f_dict.items()}\n",
    "    h = {process_key(key): process_value(value) for key, value in h_dict.items()}\n",
    "    h_exist = {process_key(key): process_value(value) for key, value in h_exist_dict.items()}\n",
    "    h_minus = {process_key(key): process_value(value) for key, value in h_minus_dict.items()}\n",
    "    h_plus = {process_key(key): process_value(value) for key, value in h_plus_dict.items()}\n",
    "    q_fuel_infr_plus = {process_key(key): process_value(value) for key, value in q_fuel_infr_plus_dict.items()}\n",
    "    q_mode_infr_plus = {process_key(key): process_value(value) for key, value in q_mode_infr_plus_dict.items()}\n",
    "    s = {process_key(key): process_value(value) for key, value in s_dict.items()}\n",
    "    n_fueling = {process_key(key): process_value(value) for key, value in n_fueling_dict.items()}\n",
    "\n",
    "    output_data = {\"budget_penalty_minus\": budget_penalty_minus, \"budget_penalty_plus\": budget_penalty_plus, \"detour_time\": detour_time, \"f\": f, \"h\": h, \"h_exist\": h_exist, \"h_minus\": h_minus, \"h_plus\": h_plus, \"q_fuel_infr_plus\": q_fuel_infr_plus, \"q_mode_infr_plus\": q_mode_infr_plus, \"s\": s, \"n_fueling\": n_fueling}\n",
    "\n",
    "    return input_data, output_data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting detour time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current path: c:\\Github\\iDesignRES_transcompmodel\\examples\n",
      "File results: c:\\Github\\iDesignRES_transcompmodel\\examples\\results\n",
      "c:/results\n",
      "Normalized path: c:\\results\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Github\\\\iDesignRES_transcompmodel\\\\examples\\\\results\\\\testing_FAST_2025-02-11_14-45-35_n_fueling_dict.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m case_study_input \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cs \u001b[38;5;129;01min\u001b[39;00m case_studies:\n\u001b[1;32m----> 6\u001b[0m     input_data, output_data \u001b[38;5;241m=\u001b[39m \u001b[43mread_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_file_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     case_study_output[cs] \u001b[38;5;241m=\u001b[39m output_data\n\u001b[0;32m      8\u001b[0m     case_study_input[cs] \u001b[38;5;241m=\u001b[39m input_data\n",
      "Cell \u001b[1;32mIn[16], line 17\u001b[0m, in \u001b[0;36mread_data\u001b[1;34m(case_study_name, input_file_name)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(folder_input \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m input_file_name) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     15\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(file)\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcase_study_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_n_fueling_dict.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     18\u001b[0m     n_fueling_dict\u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(file)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(file_results \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m case_study_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_budget_penalty_minus_dict.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Github\\\\iDesignRES_transcompmodel\\\\examples\\\\results\\\\testing_FAST_2025-02-11_14-45-35_n_fueling_dict.yaml'"
     ]
    }
   ],
   "source": [
    "case_studies = [\"testing_FAST_2025-02-11_14-45-35\"]\n",
    "input_file_name = \"transport_data_years_v65_FAST_DENSIFICATION.yaml\"\n",
    "case_study_output = {}\n",
    "case_study_input = {}\n",
    "for cs in case_studies:\n",
    "    input_data, output_data = read_data(cs, input_file_name)\n",
    "    case_study_output[cs] = output_data\n",
    "    case_study_input[cs] = input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m detour_times_at_edge \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 2\u001b[0m model_parameters \u001b[38;5;241m=\u001b[39m \u001b[43minput_data\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      3\u001b[0m Y \u001b[38;5;241m=\u001b[39m model_parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      4\u001b[0m y_init \u001b[38;5;241m=\u001b[39m model_parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_init\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_data' is not defined"
     ]
    }
   ],
   "source": [
    "detour_times_at_edge = {}\n",
    "model_parameters = input_data[\"Model\"]\n",
    "Y = model_parameters[\"Y\"]\n",
    "y_init = model_parameters[\"y_init\"]\n",
    "pre_y = model_parameters[\"pre_y\"]\n",
    "product_list = input_data[\"Product\"]\n",
    "odpair_list = input_data[\"Odpair\"]\n",
    "path_list = input_data[\"Path\"]\n",
    "techvehicle_list = input_data[\"TechVehicle\"]\n",
    "fuel_list = input_data[\"Fuel\"]\n",
    "geometric_element_list = input_data[\"GeographicElement\"]\n",
    "\n",
    "odpair_list_dict = {item[\"id\"]: item for item in odpair_list}\n",
    "techvehicle_list_dict = {item[\"id\"]: item for item in techvehicle_list}\n",
    "product_list_dict = {item[\"id\"]: item for item in product_list}\n",
    "path_list_dict = {item[\"id\"]: item for item in path_list}\n",
    "fuel_list_dict = {item[\"id\"]: item for item in fuel_list}\n",
    "geometric_element_list_dict = {item[\"id\"]: item for item in geometric_element_list}\n",
    "\n",
    "\n",
    "G = pre_y + Y\n",
    "g_init = y_init - pre_y\n",
    "Y_end = y_init + Y - 1\n",
    "\n",
    "geom_id = 12\n",
    "fuel_id = 2\n",
    "for cs in case_studies:\n",
    "    detour_time = case_study_output[cs][\"detour_time\"]\n",
    "    n_fueling = case_study_output[cs][\"n_fueling\"]\n",
    "    for y in range(y, Y_end + 1):\n",
    "        detour_times_sum = sum([detour_time[(y, (p, r, odpair_list[r][\"path_id\"], geom_id), fuel_id)] for r in odpair_list_dict.keys() for k in odpair_list_dict for p in product_list_dict.keys() if (y, (p, r, odpair_list[r][\"path_id\"], geom_id), fuel_id) in detour_time.keys()])    \n",
    "        n_fueling_sum = sum([n_fueling[(y, (p, r, odpair_list[r][\"path_id\"], geom_id), fuel_id)] for r in odpair_list_dict.keys() for k in odpair_list_dict for p in product_list_dict.keys() if (y, (p, r, odpair_list[r][\"path_id\"], geom_id), fuel_id) in n_fueling.keys()])    \n",
    "        detour_times_at_edge[(y, fuel_id)] = detour_times_sum / n_fueling_sum\n",
    "\n",
    "print(detour_times_at_edge)\n",
    "         \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transcomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
